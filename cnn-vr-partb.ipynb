{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport torch \nfrom torch import optim, cuda\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-22T12:04:59.483639Z","iopub.execute_input":"2023-03-22T12:04:59.484632Z","iopub.status.idle":"2023-03-22T12:04:59.504303Z","shell.execute_reply.started":"2023-03-22T12:04:59.484585Z","shell.execute_reply":"2023-03-22T12:04:59.503163Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"/kaggle/input/vrpbpart2/resized/Horses/45.jpg\n/kaggle/input/vrpbpart2/resized/Horses/56.jpg\n/kaggle/input/vrpbpart2/resized/Horses/89.jpg\n/kaggle/input/vrpbpart2/resized/Horses/20.jpg\n/kaggle/input/vrpbpart2/resized/Horses/58.jpg\n/kaggle/input/vrpbpart2/resized/Horses/6.jpg\n/kaggle/input/vrpbpart2/resized/Horses/76.jpg\n/kaggle/input/vrpbpart2/resized/Horses/71.jpg\n/kaggle/input/vrpbpart2/resized/Horses/5.jpg\n/kaggle/input/vrpbpart2/resized/Horses/8.jpg\n/kaggle/input/vrpbpart2/resized/Horses/84.jpg\n/kaggle/input/vrpbpart2/resized/Horses/85.jpg\n/kaggle/input/vrpbpart2/resized/Horses/67.jpg\n/kaggle/input/vrpbpart2/resized/Horses/82.jpg\n/kaggle/input/vrpbpart2/resized/Horses/30.jpg\n/kaggle/input/vrpbpart2/resized/Horses/97.jpg\n/kaggle/input/vrpbpart2/resized/Horses/38.jpg\n/kaggle/input/vrpbpart2/resized/Horses/42.jpg\n/kaggle/input/vrpbpart2/resized/Horses/33.jpg\n/kaggle/input/vrpbpart2/resized/Horses/10.jpg\n/kaggle/input/vrpbpart2/resized/Horses/54.jpg\n/kaggle/input/vrpbpart2/resized/Horses/62.jpg\n/kaggle/input/vrpbpart2/resized/Horses/35.jpg\n/kaggle/input/vrpbpart2/resized/Horses/61.jpg\n/kaggle/input/vrpbpart2/resized/Horses/59.jpg\n/kaggle/input/vrpbpart2/resized/Horses/73.jpg\n/kaggle/input/vrpbpart2/resized/Horses/98.jpg\n/kaggle/input/vrpbpart2/resized/Horses/41.jpg\n/kaggle/input/vrpbpart2/resized/Horses/94.jpg\n/kaggle/input/vrpbpart2/resized/Horses/60.jpg\n/kaggle/input/vrpbpart2/resized/Horses/57.jpg\n/kaggle/input/vrpbpart2/resized/Horses/91.jpg\n/kaggle/input/vrpbpart2/resized/Horses/9.jpg\n/kaggle/input/vrpbpart2/resized/Horses/99.jpg\n/kaggle/input/vrpbpart2/resized/Horses/37.jpg\n/kaggle/input/vrpbpart2/resized/Horses/1.jpg\n/kaggle/input/vrpbpart2/resized/Horses/69.jpg\n/kaggle/input/vrpbpart2/resized/Horses/75.jpg\n/kaggle/input/vrpbpart2/resized/Horses/81.jpg\n/kaggle/input/vrpbpart2/resized/Horses/46.jpg\n/kaggle/input/vrpbpart2/resized/Horses/44.jpg\n/kaggle/input/vrpbpart2/resized/Horses/65.jpg\n/kaggle/input/vrpbpart2/resized/Horses/50.jpg\n/kaggle/input/vrpbpart2/resized/Horses/29.jpg\n/kaggle/input/vrpbpart2/resized/Horses/79.jpg\n/kaggle/input/vrpbpart2/resized/Horses/16.jpg\n/kaggle/input/vrpbpart2/resized/Horses/55.jpg\n/kaggle/input/vrpbpart2/resized/Horses/23.jpg\n/kaggle/input/vrpbpart2/resized/Horses/7.jpg\n/kaggle/input/vrpbpart2/resized/Horses/77.jpg\n/kaggle/input/vrpbpart2/resized/Horses/80.jpg\n/kaggle/input/vrpbpart2/resized/Horses/28.jpg\n/kaggle/input/vrpbpart2/resized/Horses/22.jpg\n/kaggle/input/vrpbpart2/resized/Horses/40.jpg\n/kaggle/input/vrpbpart2/resized/Horses/48.jpg\n/kaggle/input/vrpbpart2/resized/Horses/24.jpg\n/kaggle/input/vrpbpart2/resized/Horses/88.jpg\n/kaggle/input/vrpbpart2/resized/Horses/64.jpg\n/kaggle/input/vrpbpart2/resized/Horses/31.jpg\n/kaggle/input/vrpbpart2/resized/Horses/43.jpg\n/kaggle/input/vrpbpart2/resized/Horses/13.jpg\n/kaggle/input/vrpbpart2/resized/Horses/74.jpg\n/kaggle/input/vrpbpart2/resized/Horses/68.jpg\n/kaggle/input/vrpbpart2/resized/Horses/53.jpg\n/kaggle/input/vrpbpart2/resized/Horses/83.jpg\n/kaggle/input/vrpbpart2/resized/Horses/72.jpg\n/kaggle/input/vrpbpart2/resized/Horses/32.jpg\n/kaggle/input/vrpbpart2/resized/Horses/17.jpg\n/kaggle/input/vrpbpart2/resized/Horses/26.jpg\n/kaggle/input/vrpbpart2/resized/Horses/39.jpg\n/kaggle/input/vrpbpart2/resized/Horses/86.jpg\n/kaggle/input/vrpbpart2/resized/Horses/15.jpg\n/kaggle/input/vrpbpart2/resized/Horses/12.jpg\n/kaggle/input/vrpbpart2/resized/Horses/92.jpg\n/kaggle/input/vrpbpart2/resized/Horses/11.jpg\n/kaggle/input/vrpbpart2/resized/Horses/70.jpg\n/kaggle/input/vrpbpart2/resized/Horses/34.jpg\n/kaggle/input/vrpbpart2/resized/Horses/27.jpg\n/kaggle/input/vrpbpart2/resized/Horses/51.jpg\n/kaggle/input/vrpbpart2/resized/Horses/52.jpg\n/kaggle/input/vrpbpart2/resized/Horses/21.jpg\n/kaggle/input/vrpbpart2/resized/Horses/4.jpg\n/kaggle/input/vrpbpart2/resized/Horses/95.jpg\n/kaggle/input/vrpbpart2/resized/Horses/3.jpg\n/kaggle/input/vrpbpart2/resized/Horses/36.jpg\n/kaggle/input/vrpbpart2/resized/Horses/96.jpg\n/kaggle/input/vrpbpart2/resized/Horses/63.jpg\n/kaggle/input/vrpbpart2/resized/Horses/19.jpg\n/kaggle/input/vrpbpart2/resized/Horses/87.jpg\n/kaggle/input/vrpbpart2/resized/Horses/47.jpg\n/kaggle/input/vrpbpart2/resized/Horses/93.jpg\n/kaggle/input/vrpbpart2/resized/Horses/14.jpg\n/kaggle/input/vrpbpart2/resized/Horses/18.jpg\n/kaggle/input/vrpbpart2/resized/Horses/78.jpg\n/kaggle/input/vrpbpart2/resized/Horses/49.jpg\n/kaggle/input/vrpbpart2/resized/Horses/66.jpg\n/kaggle/input/vrpbpart2/resized/Horses/2.jpg\n/kaggle/input/vrpbpart2/resized/Horses/90.jpg\n/kaggle/input/vrpbpart2/resized/Horses/25.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/45.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/56.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/20.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/58.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/6.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/76.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/71.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/5.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/8.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/67.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/30.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/38.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/42.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/33.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/10.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/54.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/62.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/35.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/61.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/59.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/73.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/41.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/60.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/57.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/9.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/37.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/1.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/69.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/75.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/46.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/44.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/65.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/50.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/29.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/79.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/16.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/55.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/23.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/7.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/77.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/80.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/28.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/22.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/40.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/48.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/24.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/64.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/31.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/43.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/13.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/74.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/68.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/53.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/72.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/32.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/17.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/26.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/39.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/15.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/12.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/11.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/70.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/34.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/27.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/51.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/52.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/21.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/4.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/3.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/36.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/63.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/19.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/47.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/14.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/18.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/78.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/49.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/66.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/2.jpg\n/kaggle/input/vrpbpart2/resized/Bikes/25.jpg\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nimport pickle\nfrom os import listdir, makedirs\nfrom os.path import isfile, join, exists, isdir\nfrom sklearn.cluster import KMeans\nfrom sklearn import svm\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:04:59.891203Z","iopub.execute_input":"2023-03-22T12:04:59.891547Z","iopub.status.idle":"2023-03-22T12:04:59.897049Z","shell.execute_reply.started":"2023-03-22T12:04:59.891518Z","shell.execute_reply":"2023-03-22T12:04:59.895922Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"cuda = cuda.is_available()\nprint(f'Train on gpu: {cuda}')\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:05:00.085183Z","iopub.execute_input":"2023-03-22T12:05:00.085945Z","iopub.status.idle":"2023-03-22T12:05:00.094163Z","shell.execute_reply.started":"2023-03-22T12:05:00.085914Z","shell.execute_reply":"2023-03-22T12:05:00.093226Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Train on gpu: True\n","output_type":"stream"}]},{"cell_type":"code","source":"rdir_path = '/kaggle/input/vrpbpart2/resized/'","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:05:00.400860Z","iopub.execute_input":"2023-03-22T12:05:00.401631Z","iopub.status.idle":"2023-03-22T12:05:00.406297Z","shell.execute_reply.started":"2023-03-22T12:05:00.401590Z","shell.execute_reply":"2023-03-22T12:05:00.405176Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# this function gets the image names according to their path as well as gives them a label according to the class.\ndef loadDataset():\n    imgs = []\n    labels = []\n    label = -1\n    \n    dirnames = [f for f in os.listdir(rdir_path) if os.path.isdir(os.path.join(rdir_path, f))]\n    \n    for directory in dirnames:\n        label = label + 1\n        path = rdir_path+'/'+directory\n        filenames = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n        \n        for file in filenames:\n            imgPath = path+'/'+file\n            imgs.append(imgPath)\n            labels.append(label)\n    \n    return (imgs,labels)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:05:00.686869Z","iopub.execute_input":"2023-03-22T12:05:00.687144Z","iopub.status.idle":"2023-03-22T12:05:00.694409Z","shell.execute_reply.started":"2023-03-22T12:05:00.687118Z","shell.execute_reply":"2023-03-22T12:05:00.693249Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# this function is used to get all the images of a particular class.\ndef getImgs(imgsPath):\n    imgs = []\n    for imgName in imgsPath:\n        img = cv2.imread(imgName)\n        imgs.append(img)\n    imgs = np.asarray(imgs)\n    return imgs","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:05:01.091480Z","iopub.execute_input":"2023-03-22T12:05:01.092058Z","iopub.status.idle":"2023-03-22T12:05:01.098809Z","shell.execute_reply.started":"2023-03-22T12:05:01.092027Z","shell.execute_reply":"2023-03-22T12:05:01.097816Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# load the dataset\ndataset = loadDataset()\n\n# train-test split the images.\ntrain_ds,test_ds,train_labels,test_labels=train_test_split(\n                                                    dataset[0],dataset[1],train_size=0.8,\n                                                    random_state=77,shuffle=True,stratify=dataset[1])\n\ntrain_ds = getImgs(train_ds)\ntest_ds = getImgs(test_ds)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:05:01.536722Z","iopub.execute_input":"2023-03-22T12:05:01.537639Z","iopub.status.idle":"2023-03-22T12:05:02.321543Z","shell.execute_reply.started":"2023-03-22T12:05:01.537601Z","shell.execute_reply":"2023-03-22T12:05:02.320456Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# ## Loading images and labels\n# (train_ds, train_labels), (test_ds, test_labels) = tfds.load(\n#     \"tf_flowers\",\n#     split=[\"train[:70%]\", \"train[:30%]\"], ## Train test split\n#     batch_size=-1,\n#     as_supervised=True,  # Include labels\n# )\n\n# ## Resizing images\n# train_ds = tf.image.resize(train_ds, (150, 150))\n# test_ds = tf.image.resize(test_ds, (150, 150))\n\n## Transforming labels to correct format\ntrain_labels_enc = to_categorical(train_labels, num_classes=2)\ntest_labels_enc = to_categorical(test_labels, num_classes=2)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:05:02.323582Z","iopub.execute_input":"2023-03-22T12:05:02.324223Z","iopub.status.idle":"2023-03-22T12:05:02.331827Z","shell.execute_reply.started":"2023-03-22T12:05:02.324176Z","shell.execute_reply":"2023-03-22T12:05:02.330687Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\n\n## Loading VGG16 model\nbase_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=train_ds[0].shape)\nbase_model.trainable = False ## Not trainable weights\n\n## Preprocessing input\ntrain_ds = preprocess_input(train_ds) \ntest_ds = preprocess_input(test_ds)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:05:02.336399Z","iopub.execute_input":"2023-03-22T12:05:02.336684Z","iopub.status.idle":"2023-03-22T12:05:02.714590Z","shell.execute_reply.started":"2023-03-22T12:05:02.336657Z","shell.execute_reply":"2023-03-22T12:05:02.713521Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"base_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:05:02.786331Z","iopub.execute_input":"2023-03-22T12:05:02.786660Z","iopub.status.idle":"2023-03-22T12:05:02.827348Z","shell.execute_reply.started":"2023-03-22T12:05:02.786628Z","shell.execute_reply":"2023-03-22T12:05:02.826574Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Model: \"vgg16\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_2 (InputLayer)        [(None, 180, 280, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 180, 280, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 180, 280, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 90, 140, 64)       0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 90, 140, 128)      73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 90, 140, 128)      147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 45, 70, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 45, 70, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 45, 70, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 45, 70, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 22, 35, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 22, 35, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 22, 35, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 22, 35, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 11, 17, 512)       0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 11, 17, 512)       2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 11, 17, 512)       2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 11, 17, 512)       2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 5, 8, 512)         0         \n                                                                 \n=================================================================\nTotal params: 14,714,688\nTrainable params: 0\nNon-trainable params: 14,714,688\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras import layers, models\n\nflatten_layer = layers.Flatten()\ndense_layer_1 = layers.Dense(50, activation='relu')\ndense_layer_2 = layers.Dense(20, activation='relu')\nprediction_layer = layers.Dense(2, activation='softmax')\n\n\nmodel = models.Sequential([\n    base_model,\n    flatten_layer,\n    dense_layer_1,\n    dense_layer_2,\n    prediction_layer\n])","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:05:03.176230Z","iopub.execute_input":"2023-03-22T12:05:03.176528Z","iopub.status.idle":"2023-03-22T12:05:03.274815Z","shell.execute_reply.started":"2023-03-22T12:05:03.176499Z","shell.execute_reply":"2023-03-22T12:05:03.273919Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy'],\n)\n\n\nes = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n\nmodel.fit(train_ds, train_labels_enc, epochs=50, validation_split=0.2, batch_size=32, callbacks=[es])","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:05:04.098499Z","iopub.execute_input":"2023-03-22T12:05:04.099189Z","iopub.status.idle":"2023-03-22T12:05:35.176716Z","shell.execute_reply.started":"2023-03-22T12:05:04.099151Z","shell.execute_reply":"2023-03-22T12:05:35.175730Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Epoch 1/50\n4/4 [==============================] - 27s 3s/step - loss: 2.2075 - accuracy: 0.8246 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\nEpoch 2/50\n4/4 [==============================] - 1s 174ms/step - loss: 0.0133 - accuracy: 0.9912 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\nEpoch 3/50\n4/4 [==============================] - 1s 184ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\nEpoch 4/50\n4/4 [==============================] - 1s 173ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\nEpoch 5/50\n4/4 [==============================] - 1s 181ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\nEpoch 6/50\n4/4 [==============================] - 1s 195ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7fccf5f6fcd0>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Evaluate on test data\")\nresults = model.evaluate(test_ds, test_labels_enc, batch_size=32)\nprint(\"test loss, test acc:\", results)","metadata":{"execution":{"iopub.status.busy":"2023-03-13T07:41:01.486784Z","iopub.execute_input":"2023-03-13T07:41:01.487329Z","iopub.status.idle":"2023-03-13T07:41:31.209036Z","shell.execute_reply.started":"2023-03-13T07:41:01.487272Z","shell.execute_reply":"2023-03-13T07:41:31.207865Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Evaluate on test data\n35/35 [==============================] - 4s 114ms/step - loss: 0.1750 - accuracy: 0.9482\ntest loss, test acc: [0.17497128248214722, 0.9482288956642151]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:17:12.877319Z","iopub.execute_input":"2023-03-22T12:17:12.877687Z","iopub.status.idle":"2023-03-22T12:17:27.470417Z","shell.execute_reply.started":"2023-03-22T12:17:12.877653Z","shell.execute_reply":"2023-03-22T12:17:27.469352Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"RF_model = RandomForestClassifier(n_estimators = 25, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:17:27.472172Z","iopub.execute_input":"2023-03-22T12:17:27.472514Z","iopub.status.idle":"2023-03-22T12:17:27.480085Z","shell.execute_reply.started":"2023-03-22T12:17:27.472484Z","shell.execute_reply":"2023-03-22T12:17:27.478297Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# Now we predict on the training set using the base model, \n# this time without adding the custom fully connected layers.\nfeature_extractor = base_model.predict(train_ds)\nfeatures = feature_extractor.reshape(feature_extractor.shape[0],-1)\n\nX_for_RF = features","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:17:27.482103Z","iopub.execute_input":"2023-03-22T12:17:27.482568Z","iopub.status.idle":"2023-03-22T12:17:33.045275Z","shell.execute_reply.started":"2023-03-22T12:17:27.482527Z","shell.execute_reply":"2023-03-22T12:17:33.043835Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"5/5 [==============================] - 4s 876ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"RF_model.fit(X_for_RF,train_labels_enc)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:17:33.052066Z","iopub.execute_input":"2023-03-22T12:17:33.054076Z","iopub.status.idle":"2023-03-22T12:17:33.136209Z","shell.execute_reply.started":"2023-03-22T12:17:33.053910Z","shell.execute_reply":"2023-03-22T12:17:33.135274Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier(n_estimators=25, random_state=42)"},"metadata":{}}]},{"cell_type":"code","source":"# send test data through same feature extraction process.\nfeature_extractor_test = base_model.predict(test_ds)\ntest_features = feature_extractor_test.reshape(feature_extractor_test.shape[0],-1)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:17:33.137527Z","iopub.execute_input":"2023-03-22T12:17:33.137913Z","iopub.status.idle":"2023-03-22T12:17:34.527158Z","shell.execute_reply.started":"2023-03-22T12:17:33.137876Z","shell.execute_reply":"2023-03-22T12:17:34.526178Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"2/2 [==============================] - 1s 1s/step\n","output_type":"stream"}]},{"cell_type":"code","source":"preditction_RF = RF_model.predict(test_features)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:17:46.854182Z","iopub.execute_input":"2023-03-22T12:17:46.854569Z","iopub.status.idle":"2023-03-22T12:17:46.866203Z","shell.execute_reply.started":"2023-03-22T12:17:46.854532Z","shell.execute_reply":"2023-03-22T12:17:46.864941Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nprint(\"Accuracy : \",metrics.accuracy_score(test_labels_enc,preditction_RF))","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:17:47.670089Z","iopub.execute_input":"2023-03-22T12:17:47.671136Z","iopub.status.idle":"2023-03-22T12:17:47.690407Z","shell.execute_reply.started":"2023-03-22T12:17:47.671079Z","shell.execute_reply":"2023-03-22T12:17:47.689450Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Accuracy :  1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.svm import SVC","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:18:23.023437Z","iopub.execute_input":"2023-03-22T12:18:23.024151Z","iopub.status.idle":"2023-03-22T12:18:23.029020Z","shell.execute_reply.started":"2023-03-22T12:18:23.024112Z","shell.execute_reply":"2023-03-22T12:18:23.027967Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"svclassifier = SVC(kernel = 'rbf',gamma = 'scale', random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:18:23.362141Z","iopub.execute_input":"2023-03-22T12:18:23.363053Z","iopub.status.idle":"2023-03-22T12:18:23.367932Z","shell.execute_reply.started":"2023-03-22T12:18:23.363014Z","shell.execute_reply":"2023-03-22T12:18:23.366645Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# from sklearn import preprocessing\n# le = preprocessing.LabelEncoder()\n# le.fit(train_labels)\n# train_labels_svm = le.inverse_transform(train_labels)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:18:23.794723Z","iopub.execute_input":"2023-03-22T12:18:23.795697Z","iopub.status.idle":"2023-03-22T12:18:23.800254Z","shell.execute_reply.started":"2023-03-22T12:18:23.795656Z","shell.execute_reply":"2023-03-22T12:18:23.798992Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# we do the same thing that we did for random forests.\nX_for_SVM = features\nsvclassifier.fit(X_for_SVM,train_labels)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:18:25.152314Z","iopub.execute_input":"2023-03-22T12:18:25.152768Z","iopub.status.idle":"2023-03-22T12:18:25.392840Z","shell.execute_reply.started":"2023-03-22T12:18:25.152732Z","shell.execute_reply":"2023-03-22T12:18:25.391470Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"SVC(random_state=42)"},"metadata":{}}]},{"cell_type":"code","source":"svm_preds = svclassifier.predict(test_features)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:18:26.328678Z","iopub.execute_input":"2023-03-22T12:18:26.329652Z","iopub.status.idle":"2023-03-22T12:18:26.382140Z","shell.execute_reply.started":"2023-03-22T12:18:26.329603Z","shell.execute_reply":"2023-03-22T12:18:26.381089Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nprint(\"Accuracy : \",metrics.accuracy_score(test_labels,svm_preds))","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:18:27.388726Z","iopub.execute_input":"2023-03-22T12:18:27.389432Z","iopub.status.idle":"2023-03-22T12:18:27.395104Z","shell.execute_reply.started":"2023-03-22T12:18:27.389387Z","shell.execute_reply":"2023-03-22T12:18:27.393554Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"Accuracy :  1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}